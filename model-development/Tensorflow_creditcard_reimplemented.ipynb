{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkhdO9CzK5f9",
        "outputId": "361fc0b5-58bf-46dc-e412-ac98cdf1e3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.3306 - loss: 1.1813 - val_accuracy: 0.7100 - val_loss: 0.6029 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7120 - loss: 0.6583 - val_accuracy: 0.7100 - val_loss: 0.6904 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7176 - loss: 0.6797 - val_accuracy: 0.7100 - val_loss: 0.5997 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7100 - loss: 0.6124 - val_accuracy: 0.7100 - val_loss: 0.6081 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6955 - loss: 0.6170 - val_accuracy: 0.7100 - val_loss: 0.5913 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7179 - loss: 0.5971 - val_accuracy: 0.7100 - val_loss: 0.5826 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7139 - loss: 0.5903 - val_accuracy: 0.7100 - val_loss: 0.5762 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7259 - loss: 0.5678 - val_accuracy: 0.7100 - val_loss: 0.5640 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7131 - loss: 0.5699 - val_accuracy: 0.7100 - val_loss: 0.5538 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7006 - loss: 0.5592 - val_accuracy: 0.7100 - val_loss: 0.5363 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7312 - loss: 0.5379 - val_accuracy: 0.7100 - val_loss: 0.5236 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7377 - loss: 0.5226 - val_accuracy: 0.7400 - val_loss: 0.5158 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7490 - loss: 0.5073 - val_accuracy: 0.7200 - val_loss: 0.5093 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7571 - loss: 0.5108 - val_accuracy: 0.7300 - val_loss: 0.5070 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7773 - loss: 0.4767 - val_accuracy: 0.7300 - val_loss: 0.5002 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7600 - loss: 0.4855 - val_accuracy: 0.7200 - val_loss: 0.4995 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7635 - loss: 0.4911 - val_accuracy: 0.7200 - val_loss: 0.4940 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7677 - loss: 0.4796 - val_accuracy: 0.7200 - val_loss: 0.4905 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7635 - loss: 0.4754 - val_accuracy: 0.7200 - val_loss: 0.4903 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7774 - loss: 0.4599 - val_accuracy: 0.7500 - val_loss: 0.4886 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7674 - loss: 0.4774 - val_accuracy: 0.7400 - val_loss: 0.4877 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7538 - loss: 0.4777 - val_accuracy: 0.7600 - val_loss: 0.4857 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7566 - loss: 0.4681 - val_accuracy: 0.7600 - val_loss: 0.4846 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7622 - loss: 0.4698 - val_accuracy: 0.7600 - val_loss: 0.4818 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7514 - loss: 0.4757 - val_accuracy: 0.7500 - val_loss: 0.4837 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7707 - loss: 0.4491 - val_accuracy: 0.7500 - val_loss: 0.4813 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7741 - loss: 0.4514 - val_accuracy: 0.7500 - val_loss: 0.4796 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4577 - val_accuracy: 0.7600 - val_loss: 0.4797 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7779 - loss: 0.4567 - val_accuracy: 0.7600 - val_loss: 0.4780 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 0.4609 - val_accuracy: 0.7400 - val_loss: 0.4796 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4626 - val_accuracy: 0.7400 - val_loss: 0.4785 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.4517 - val_accuracy: 0.7400 - val_loss: 0.4785 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7663 - loss: 0.4509 - val_accuracy: 0.7400 - val_loss: 0.4774 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.4546 - val_accuracy: 0.7600 - val_loss: 0.4783 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7789 - loss: 0.4331 - val_accuracy: 0.7600 - val_loss: 0.4769 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4364 - val_accuracy: 0.7500 - val_loss: 0.4787 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7863 - loss: 0.4453 - val_accuracy: 0.7600 - val_loss: 0.4769 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.4283 - val_accuracy: 0.7800 - val_loss: 0.4777 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7876 - loss: 0.4406 - val_accuracy: 0.7500 - val_loss: 0.4757 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7854 - loss: 0.4314 - val_accuracy: 0.7600 - val_loss: 0.4713 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7974 - loss: 0.4270 - val_accuracy: 0.7500 - val_loss: 0.4702 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7857 - loss: 0.4253 - val_accuracy: 0.7400 - val_loss: 0.4692 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8036 - loss: 0.4196 - val_accuracy: 0.7400 - val_loss: 0.4668 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8016 - loss: 0.4265 - val_accuracy: 0.7200 - val_loss: 0.4664 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4163 - val_accuracy: 0.7400 - val_loss: 0.4671 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4168 - val_accuracy: 0.7400 - val_loss: 0.4673 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7945 - loss: 0.4095 - val_accuracy: 0.7400 - val_loss: 0.4631 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8038 - loss: 0.4107 - val_accuracy: 0.7500 - val_loss: 0.4604 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8071 - loss: 0.3944 - val_accuracy: 0.7600 - val_loss: 0.4584 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8005 - loss: 0.4075 - val_accuracy: 0.7600 - val_loss: 0.4574 - learning_rate: 0.0010\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7800 - loss: 0.4356\n",
            "Test accuracy: 0.7799999713897705\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate, Normalization, IntegerLookup, StringLookup, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Load dataset\n",
        "credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
        "X = credit_data.data\n",
        "y = credit_data.target.map({'good': 1, 'bad': 0}).values\n",
        "\n",
        "# Define feature columns\n",
        "discrete_features = ['installment_commitment', 'residence_since', 'num_dependents', 'existing_credits']\n",
        "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
        "continous_features = ['duration', 'credit_amount']\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "def create_tf_datasets(X, y, test_size=0.1, val_size=0.1, batch_size=128):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
        "    dataset = dataset.shuffle(buffer_size=len(X), seed=seed)\n",
        "    test_size = int(len(X) * test_size)\n",
        "    val_size = int(len(X) * val_size)\n",
        "    test_dataset = dataset.take(test_size)\n",
        "    val_dataset = dataset.skip(test_size).take(val_size)\n",
        "    train_dataset = dataset.skip(test_size + val_size)\n",
        "    return (\n",
        "        train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "batch_size = 128\n",
        "seed=2025\n",
        "train_dataset_raw, val_dataset_raw, test_dataset_raw = create_tf_datasets(X, y)\n",
        "\n",
        "# Precompute normalization statistics\n",
        "train_features = {col: X[col].values for col in X.columns}\n",
        "continuous_train_data = {col: train_features[col].astype(float) for col in continous_features}\n",
        "\n",
        "# Compute mean and variance for each continuous feature to avoid\n",
        "#unmatched batch size for the last bactch during the normalization process.\n",
        "# Normalization layers require all batches must have the same size\n",
        "normalization_stats = {}\n",
        "for col in continous_features:\n",
        "    data = continuous_train_data[col]\n",
        "    mean = np.mean(data)\n",
        "    var = np.var(data)\n",
        "    normalization_stats[col] = (mean, var)\n",
        "\n",
        "# Adapt preprocessing layers on training data only\n",
        "def create_preprocessing_layers():\n",
        "    normalizers = {}\n",
        "    for col in continous_features:\n",
        "        mean, var = normalization_stats[col]\n",
        "        normalizer = Normalization()\n",
        "        normalizer.mean = [mean]\n",
        "        normalizer.variance = [var]\n",
        "        normalizers[col] = normalizer\n",
        "\n",
        "    ordinal_encoders = {col: IntegerLookup(output_mode='int', num_oov_indices=1) for col in discrete_features}\n",
        "    categorical_encoders = {col: StringLookup(output_mode='int', num_oov_indices=1) for col in categorical_features}\n",
        "\n",
        "    # Adapt encoders\n",
        "    for batch in train_dataset_raw:\n",
        "        features, _ = batch\n",
        "        for col in discrete_features:\n",
        "            ordinal_encoders[col].adapt(features[col])\n",
        "        for col in categorical_features:\n",
        "            categorical_encoders[col].adapt(features[col])\n",
        "\n",
        "    return normalizers, ordinal_encoders, categorical_encoders\n",
        "\n",
        "normalizers, ordinal_encoders, categorical_encoders = create_preprocessing_layers()\n",
        "\n",
        "# Preprocessing integrated into the model\n",
        "def build_preprocessing_model():\n",
        "    # Inputs\n",
        "    continuous_inputs = {col: Input(shape=(1,), dtype=tf.float32, name=f\"{col}_input\") for col in continous_features}\n",
        "    discrete_inputs = {col: Input(shape=(1,), dtype=tf.int32, name=f\"{col}_input\") for col in discrete_features}\n",
        "    categorical_inputs = {col: Input(shape=(1,), dtype=tf.string, name=f\"{col}_input\") for col in categorical_features}\n",
        "\n",
        "    def log1p_cast(x):\n",
        "      x = tf.cast(x, tf.float32)\n",
        "      return tf.math.log1p(x)\n",
        "\n",
        "\n",
        "   # Preprocess continuous features (log1p and normalize)\n",
        "    processed_continuous = [\n",
        "        normalizers[col](tf.keras.layers.Lambda(log1p_cast, name=f'log1p_lambda_{col}')(continuous_inputs[col]))\n",
        "        for col in continous_features\n",
        "    ]\n",
        "\n",
        "    # Preprocess discrete numeric features\n",
        "    def cast_to_float(x):\n",
        "      return tf.cast(x, tf.float32)\n",
        "\n",
        "    processed_discrete = [\n",
        "        tf.keras.layers.Lambda(cast_to_float, name=f'cast_lambda{col}')(discrete_inputs[col]) for col in discrete_features\n",
        "    ]\n",
        "\n",
        "#(ordinal_encoders[col](discrete_inputs[col]), tf.float32\n",
        "    # Preprocess categorical features with embeddings\n",
        "    embedding_size = 8\n",
        "    embedded_features = [\n",
        "        Embedding(input_dim=categorical_encoders[col].vocabulary_size(), output_dim=embedding_size)(\n",
        "            categorical_encoders[col](categorical_inputs[col])\n",
        "        ) for col in categorical_features\n",
        "    ]\n",
        "    embedded_features = [Flatten()(embed) for embed in embedded_features]\n",
        "\n",
        "    # Concatenate all features\n",
        "    all_features = Concatenate()(processed_continuous + processed_discrete + embedded_features)\n",
        "\n",
        "    return continuous_inputs, discrete_inputs, categorical_inputs, all_features\n",
        "\n",
        "# Build the full model\n",
        "continuous_inputs, discrete_inputs, categorical_inputs, processed_features = build_preprocessing_model()\n",
        "x = Dense(128, activation='relu', kernel_initializer='he_normal')(processed_features)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(64, activation='relu',  kernel_initializer='he_normal')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Combine inputs and outputs\n",
        "model_inputs = list(continuous_inputs.values()) + list(discrete_inputs.values()) + list(categorical_inputs.values())\n",
        "model = Model(inputs=model_inputs, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Preprocess datasets for model input\n",
        "def preprocess_batch(features, labels):\n",
        "    inputs = {\n",
        "        **{f\"{col}_input\": tf.cast(features[col], tf.float32) for col in continous_features},\n",
        "        **{f\"{col}_input\": tf.cast(features[col], tf.int32) for col in discrete_features},\n",
        "        **{f\"{col}_input\": features[col] for col in categorical_features}\n",
        "    }\n",
        "    return inputs, labels\n",
        "\n",
        "train_dataset = train_dataset_raw.map(preprocess_batch).cache()\n",
        "val_dataset = val_dataset_raw.map(preprocess_batch).cache()\n",
        "test_dataset = test_dataset_raw.map(preprocess_batch).cache()\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [EarlyStopping(patience=15,\n",
        "                           restore_best_weights=True,\n",
        "                           monitor='val_loss'),\n",
        "            ReduceLROnPlateau(monitor='val_loss',\n",
        "                              fact=0.5,\n",
        "                              patience=15,\n",
        "                              min_lr=1e-6),\n",
        "            ModelCheckpoint('best_logistic_credit_model_tf.keras',\n",
        "                            monitor='val_loss',\n",
        "                            save_best_only=True)\n",
        "            ]\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Save model\n",
        "model.save('credit_model_tf_large.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtngYySIpHEQ",
        "outputId": "43e59809-f141-45ad-c610-011728269788"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-d9b8d8e6244a>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[continuous_features] = np.log1p(X[continuous_features])  # Apply log1p\n",
            "<ipython-input-6-d9b8d8e6244a>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[continuous_features] = scaler.fit_transform(X[continuous_features])  # Standardize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.6589 - loss: 0.6385 - val_accuracy: 0.6600 - val_loss: 0.6473 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7052 - loss: 0.5961 - val_accuracy: 0.6700 - val_loss: 0.6471 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7057 - loss: 0.5861 - val_accuracy: 0.6700 - val_loss: 0.6311 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7109 - loss: 0.5708 - val_accuracy: 0.6700 - val_loss: 0.6220 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7336 - loss: 0.5626 - val_accuracy: 0.6600 - val_loss: 0.6123 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7253 - loss: 0.5411 - val_accuracy: 0.6700 - val_loss: 0.6031 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7520 - loss: 0.5219 - val_accuracy: 0.6700 - val_loss: 0.5903 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7367 - loss: 0.5215 - val_accuracy: 0.6900 - val_loss: 0.5806 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7525 - loss: 0.5041 - val_accuracy: 0.7100 - val_loss: 0.5716 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7553 - loss: 0.4885 - val_accuracy: 0.7300 - val_loss: 0.5634 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7560 - loss: 0.4854 - val_accuracy: 0.7400 - val_loss: 0.5520 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7563 - loss: 0.4884 - val_accuracy: 0.7400 - val_loss: 0.5371 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7594 - loss: 0.4674 - val_accuracy: 0.7400 - val_loss: 0.5244 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7566 - loss: 0.4686 - val_accuracy: 0.7400 - val_loss: 0.5107 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7693 - loss: 0.4530 - val_accuracy: 0.7300 - val_loss: 0.4941 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7772 - loss: 0.4501 - val_accuracy: 0.7300 - val_loss: 0.4818 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7690 - loss: 0.4462 - val_accuracy: 0.7400 - val_loss: 0.4733 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7754 - loss: 0.4456 - val_accuracy: 0.7400 - val_loss: 0.4639 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7786 - loss: 0.4299 - val_accuracy: 0.7500 - val_loss: 0.4556 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8020 - loss: 0.4142 - val_accuracy: 0.7500 - val_loss: 0.4480 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7907 - loss: 0.4178 - val_accuracy: 0.7600 - val_loss: 0.4383 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7870 - loss: 0.4155 - val_accuracy: 0.7600 - val_loss: 0.4317 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8127 - loss: 0.4037 - val_accuracy: 0.7600 - val_loss: 0.4219 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8022 - loss: 0.4007 - val_accuracy: 0.7700 - val_loss: 0.4140 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8269 - loss: 0.3925 - val_accuracy: 0.7800 - val_loss: 0.4059 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8135 - loss: 0.3850 - val_accuracy: 0.7900 - val_loss: 0.4033 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8055 - loss: 0.3843 - val_accuracy: 0.7900 - val_loss: 0.3934 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8273 - loss: 0.3710 - val_accuracy: 0.7900 - val_loss: 0.3863 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8314 - loss: 0.3668 - val_accuracy: 0.8100 - val_loss: 0.3802 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8344 - loss: 0.3623 - val_accuracy: 0.8100 - val_loss: 0.3783 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8317 - loss: 0.3564 - val_accuracy: 0.8000 - val_loss: 0.3724 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8298 - loss: 0.3490 - val_accuracy: 0.8100 - val_loss: 0.3665 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8514 - loss: 0.3385 - val_accuracy: 0.8100 - val_loss: 0.3607 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8551 - loss: 0.3284 - val_accuracy: 0.8200 - val_loss: 0.3571 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8494 - loss: 0.3248 - val_accuracy: 0.8200 - val_loss: 0.3584 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8505 - loss: 0.3260 - val_accuracy: 0.8200 - val_loss: 0.3507 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8412 - loss: 0.3195 - val_accuracy: 0.8400 - val_loss: 0.3408 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8599 - loss: 0.3012 - val_accuracy: 0.8700 - val_loss: 0.3351 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8726 - loss: 0.2919 - val_accuracy: 0.8500 - val_loss: 0.3346 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8691 - loss: 0.3022 - val_accuracy: 0.8700 - val_loss: 0.3327 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8846 - loss: 0.2789 - val_accuracy: 0.8700 - val_loss: 0.3302 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8793 - loss: 0.2670 - val_accuracy: 0.8700 - val_loss: 0.3245 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8781 - loss: 0.2665 - val_accuracy: 0.8700 - val_loss: 0.3172 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8817 - loss: 0.2774 - val_accuracy: 0.8800 - val_loss: 0.3146 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8922 - loss: 0.2490 - val_accuracy: 0.8800 - val_loss: 0.3137 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9060 - loss: 0.2435 - val_accuracy: 0.8900 - val_loss: 0.3127 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8981 - loss: 0.2408 - val_accuracy: 0.8600 - val_loss: 0.3176 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8955 - loss: 0.2356 - val_accuracy: 0.8800 - val_loss: 0.3106 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9022 - loss: 0.2174 - val_accuracy: 0.8800 - val_loss: 0.3056 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9099 - loss: 0.2201 - val_accuracy: 0.8700 - val_loss: 0.3108 - learning_rate: 0.0010\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8900 - loss: 0.2581\n",
            "Test loss: 0.2581229507923126 - Test accuracy: 0.8899999856948853\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate, IntegerLookup, StringLookup, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Load dataset\n",
        "credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
        "X = credit_data.data\n",
        "y = credit_data.target.map({'good': 1, 'bad': 0}).values\n",
        "\n",
        "# Define feature columns\n",
        "discrete_features = ['installment_commitment', 'residence_since', 'num_dependents', 'existing_credits']\n",
        "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
        "continuous_features = ['duration', 'credit_amount']\n",
        "\n",
        "# Preprocess continuous features\n",
        "scaler = StandardScaler()\n",
        "X[continuous_features] = np.log1p(X[continuous_features])  # Apply log1p\n",
        "X[continuous_features] = scaler.fit_transform(X[continuous_features])  # Standardize\n",
        "\n",
        "# Create TensorFlow datasets with 80/10/10 split\n",
        "def create_tf_datasets(X, y, train_size=0.8, val_size=0.1, batch_size=128, seed=None):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
        "    dataset = dataset.shuffle(buffer_size=len(X), seed=seed)\n",
        "    n = len(X)\n",
        "    train_size = int(n * train_size)\n",
        "    val_size = int(n * val_size)\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size).take(val_size)\n",
        "    test_dataset = dataset.skip(train_size + val_size)\n",
        "    return (\n",
        "        train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "seed = 2025  # Change to None for randomness, or test 0, 1, 42, etc.\n",
        "train_dataset_raw, val_dataset_raw, test_dataset_raw = create_tf_datasets(X, y, seed=seed)\n",
        "\n",
        "# Adapt lookup layers\n",
        "def adapt_preprocessing_layers(dataset):\n",
        "    ordinal_encoders = {col: IntegerLookup(output_mode='int', num_oov_indices=1) for col in discrete_features}\n",
        "    categorical_encoders = {col: StringLookup(output_mode='int', num_oov_indices=1) for col in categorical_features}\n",
        "\n",
        "    for batch in dataset:\n",
        "        features, _ = batch\n",
        "        for col in discrete_features:\n",
        "            ordinal_encoders[col].adapt(features[col])\n",
        "        for col in categorical_features:\n",
        "            categorical_encoders[col].adapt(features[col])\n",
        "\n",
        "    return ordinal_encoders, categorical_encoders\n",
        "\n",
        "ordinal_encoders, categorical_encoders = adapt_preprocessing_layers(train_dataset_raw)\n",
        "\n",
        "# Build model with preprocessing\n",
        "def build_preprocessing_model():\n",
        "    continuous_inputs = {col: Input(shape=(1,), dtype=tf.float32, name=f\"{col}_input\") for col in continuous_features}\n",
        "    discrete_inputs = {col: Input(shape=(1,), dtype=tf.int32, name=f\"{col}_input\") for col in discrete_features}\n",
        "    categorical_inputs = {col: Input(shape=(1,), dtype=tf.string, name=f\"{col}_input\") for col in categorical_features}\n",
        "\n",
        "    processed_continuous = [continuous_inputs[col] for col in continuous_features]  # Already preprocessed\n",
        "\n",
        "    processed_discrete = [\n",
        "        Lambda(lambda x: tf.cast(ordinal_encoders[col](x), tf.float32), name=f'cast_lambda_{col}')(discrete_inputs[col])\n",
        "        for col in discrete_features\n",
        "    ]\n",
        "\n",
        "    embedding_size = 8\n",
        "    embedded_features = [\n",
        "        Flatten()(Embedding(input_dim=categorical_encoders[col].vocabulary_size(), output_dim=embedding_size)(\n",
        "            categorical_encoders[col](categorical_inputs[col])\n",
        "        )) for col in categorical_features\n",
        "    ]\n",
        "\n",
        "    all_features = Concatenate()(processed_continuous + processed_discrete + embedded_features)\n",
        "    return continuous_inputs, discrete_inputs, categorical_inputs, all_features\n",
        "\n",
        "# Build full model\n",
        "continuous_inputs, discrete_inputs, categorical_inputs, processed_features = build_preprocessing_model()\n",
        "x = Dense(128, activation='relu', kernel_initializer='he_normal')(processed_features)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_inputs = list(continuous_inputs.values()) + list(discrete_inputs.values()) + list(categorical_inputs.values())\n",
        "model = Model(inputs=model_inputs, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Preprocess datasets\n",
        "def preprocess_batch(features, labels):\n",
        "    inputs = {\n",
        "        **{f\"{col}_input\": features[col] for col in continuous_features},\n",
        "        **{f\"{col}_input\": tf.cast(features[col], tf.int32) for col in discrete_features},\n",
        "        **{f\"{col}_input\": features[col] for col in categorical_features}\n",
        "    }\n",
        "    return inputs, labels\n",
        "\n",
        "train_dataset = train_dataset_raw.map(preprocess_batch).cache()\n",
        "val_dataset = val_dataset_raw.map(preprocess_batch).cache()\n",
        "test_dataset = test_dataset_raw.map(preprocess_batch).cache()\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_logistic_credit_model_tf.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=50, callbacks=callbacks)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test loss: {test_loss} - Test accuracy: {test_acc}\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"logistic_credit_model_tf.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sTFco3ZSZnu",
        "outputId": "9226ca5b-399b-4cc2-9006-4d0b75d07726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: silence_tensorflow in /usr/local/lib/python3.11/dist-packages (1.2.3)\n",
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6770 - loss: 0.6262 - val_accuracy: 0.6600 - val_loss: 0.6637 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7074 - loss: 0.6008 - val_accuracy: 0.6600 - val_loss: 0.6368 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7094 - loss: 0.5812 - val_accuracy: 0.6600 - val_loss: 0.6222 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7162 - loss: 0.5735 - val_accuracy: 0.6700 - val_loss: 0.6110 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7318 - loss: 0.5537 - val_accuracy: 0.6800 - val_loss: 0.5961 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7249 - loss: 0.5421 - val_accuracy: 0.6900 - val_loss: 0.5762 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7470 - loss: 0.5122 - val_accuracy: 0.6900 - val_loss: 0.5608 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7504 - loss: 0.5022 - val_accuracy: 0.7300 - val_loss: 0.5480 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7774 - loss: 0.4838 - val_accuracy: 0.7500 - val_loss: 0.5421 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7627 - loss: 0.4894 - val_accuracy: 0.7400 - val_loss: 0.5346 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7578 - loss: 0.4772 - val_accuracy: 0.7600 - val_loss: 0.5261 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7587 - loss: 0.4737 - val_accuracy: 0.7500 - val_loss: 0.5127 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7603 - loss: 0.4661 - val_accuracy: 0.7400 - val_loss: 0.5016 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7729 - loss: 0.4598 - val_accuracy: 0.7400 - val_loss: 0.4883 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7690 - loss: 0.4559 - val_accuracy: 0.7400 - val_loss: 0.4768 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7706 - loss: 0.4467 - val_accuracy: 0.7600 - val_loss: 0.4660 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7577 - loss: 0.4461 - val_accuracy: 0.7700 - val_loss: 0.4559 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7632 - loss: 0.4389 - val_accuracy: 0.7800 - val_loss: 0.4498 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7921 - loss: 0.4448 - val_accuracy: 0.7700 - val_loss: 0.4434 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7988 - loss: 0.4135 - val_accuracy: 0.7800 - val_loss: 0.4369 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7859 - loss: 0.4332 - val_accuracy: 0.7800 - val_loss: 0.4276 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7949 - loss: 0.4215 - val_accuracy: 0.8100 - val_loss: 0.4217 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8139 - loss: 0.4113 - val_accuracy: 0.8200 - val_loss: 0.4150 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8065 - loss: 0.4191 - val_accuracy: 0.8100 - val_loss: 0.4115 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8099 - loss: 0.4012 - val_accuracy: 0.8000 - val_loss: 0.4064 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8082 - loss: 0.3985 - val_accuracy: 0.8200 - val_loss: 0.3987 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8223 - loss: 0.4057 - val_accuracy: 0.8400 - val_loss: 0.3955 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8146 - loss: 0.3843 - val_accuracy: 0.8500 - val_loss: 0.3936 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8129 - loss: 0.3799 - val_accuracy: 0.8300 - val_loss: 0.3905 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8256 - loss: 0.3681 - val_accuracy: 0.8400 - val_loss: 0.3884 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8278 - loss: 0.3665 - val_accuracy: 0.8600 - val_loss: 0.3840 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8408 - loss: 0.3650 - val_accuracy: 0.8500 - val_loss: 0.3738 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8492 - loss: 0.3489 - val_accuracy: 0.8600 - val_loss: 0.3731 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8358 - loss: 0.3549 - val_accuracy: 0.8800 - val_loss: 0.3653 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - loss: 0.3428 - val_accuracy: 0.8700 - val_loss: 0.3656 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8394 - loss: 0.3389 - val_accuracy: 0.8800 - val_loss: 0.3638 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8501 - loss: 0.3248 - val_accuracy: 0.8800 - val_loss: 0.3593 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8600 - loss: 0.3244 - val_accuracy: 0.8800 - val_loss: 0.3579 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8668 - loss: 0.3064 - val_accuracy: 0.8800 - val_loss: 0.3539 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8703 - loss: 0.3101 - val_accuracy: 0.8800 - val_loss: 0.3521 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8790 - loss: 0.2912 - val_accuracy: 0.8700 - val_loss: 0.3482 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8592 - loss: 0.2937 - val_accuracy: 0.8800 - val_loss: 0.3412 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8744 - loss: 0.2932 - val_accuracy: 0.8700 - val_loss: 0.3391 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8741 - loss: 0.2854 - val_accuracy: 0.8600 - val_loss: 0.3389 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8759 - loss: 0.2746 - val_accuracy: 0.8700 - val_loss: 0.3339 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8941 - loss: 0.2627 - val_accuracy: 0.8700 - val_loss: 0.3244 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.2486 - val_accuracy: 0.8900 - val_loss: 0.3271 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9046 - loss: 0.2487 - val_accuracy: 0.8800 - val_loss: 0.3147 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2534 - val_accuracy: 0.8700 - val_loss: 0.3288 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.2377 - val_accuracy: 0.8700 - val_loss: 0.3177 - learning_rate: 0.0010\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9000 - loss: 0.2922\n",
            "Test loss: 0.29223084449768066 - Test accuracy: 0.8999999761581421\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip install silence_tensorflow\n",
        "from silence_tensorflow import silence_tensorflow\n",
        "silence_tensorflow()\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate, BatchNormalization, IntegerLookup, StringLookup\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Load dataset\n",
        "credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
        "X = credit_data.data\n",
        "y = credit_data.target.map({'good': 1, 'bad': 0}).values\n",
        "\n",
        "# Define feature columns\n",
        "discrete_features = ['installment_commitment', 'residence_since', 'num_dependents', 'existing_credits']\n",
        "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
        "continuous_features = ['duration', 'credit_amount']\n",
        "\n",
        "# Create TensorFlow datasets with 80/10/10 split\n",
        "def create_tf_datasets(X, y, train_size=0.8, val_size=0.1, batch_size=128, seed=None):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
        "    dataset = dataset.shuffle(buffer_size=len(X), seed=seed)  # Configurable seed\n",
        "    n = len(X)\n",
        "    train_size = int(n * train_size)\n",
        "    val_size = int(n * val_size)\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size).take(val_size)\n",
        "    test_dataset = dataset.skip(train_size + val_size)\n",
        "    return (\n",
        "        train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "# Try different seeds (None for unseeded, or specific values)\n",
        "seed = 2025  # Change to None for randomness, or test 0, 1, 42, etc.\n",
        "train_dataset_raw, val_dataset_raw, test_dataset_raw = create_tf_datasets(X, y, seed=seed)\n",
        "\n",
        "# Adapt lookup layers\n",
        "def adapt_preprocessing_layers(dataset):\n",
        "    ordinal_encoders = {col: IntegerLookup(output_mode='int', num_oov_indices=1) for col in discrete_features}\n",
        "    categorical_encoders = {col: StringLookup(output_mode='int', num_oov_indices=1) for col in categorical_features}\n",
        "\n",
        "    for batch in dataset:\n",
        "        features, _ = batch\n",
        "        for col in discrete_features:\n",
        "            ordinal_encoders[col].adapt(features[col])\n",
        "        for col in categorical_features:\n",
        "            categorical_encoders[col].adapt(features[col])\n",
        "\n",
        "    return ordinal_encoders, categorical_encoders\n",
        "\n",
        "ordinal_encoders, categorical_encoders = adapt_preprocessing_layers(train_dataset_raw)\n",
        "\n",
        "def log1p_with_shape(x):\n",
        "    return tf.math.log1p(x)\n",
        "\n",
        "def cast_to_float_with_shape(x):\n",
        "    return tf.cast(x, tf.float32)\n",
        "\n",
        "\n",
        "# Build model with preprocessing\n",
        "def build_preprocessing_model():\n",
        "    continuous_inputs = {col: Input(shape=(1,), dtype=tf.float32, name=f\"{col}_input\") for col in continuous_features}\n",
        "    discrete_inputs = {col: Input(shape=(1,), dtype=tf.int32, name=f\"{col}_input\") for col in discrete_features}\n",
        "    categorical_inputs = {col: Input(shape=(1,), dtype=tf.string, name=f\"{col}_input\") for col in categorical_features}\n",
        "\n",
        "\n",
        "    processed_continuous = [\n",
        "        tf.keras.layers.Lambda(\n",
        "            lambda x: (x - tf.reduce_mean(x)) / tf.math.reduce_std(x),\n",
        "            output_shape=(1,),\n",
        "            name=f'standardize_lambda_{col}'\n",
        "        )(\n",
        "            tf.keras.layers.Lambda(\n",
        "                lambda x: log1p_with_shape(x),\n",
        "                output_shape=(1,),\n",
        "                name=f'log1p_lambda_{col}'\n",
        "            )\n",
        "        (continuous_inputs[col])) for col in continuous_features\n",
        "    ]\n",
        "\n",
        "\n",
        "    #processed_continuous = [\n",
        "    #    BatchNormalization(momentum=0.1, epsilon=1e-5)(\n",
        "    #        tf.keras.layers.Lambda(\n",
        "    #            log1p_with_shape,\n",
        "    #            output_shape=(1,),\n",
        "    #            name=f'log1p_lambda_{col}'\n",
        "    #        )(continuous_inputs[col])\n",
        "    #    ) for col in continuous_features\n",
        "    #]\n",
        "\n",
        "\n",
        "    processed_discrete = [\n",
        "        tf.keras.layers.Lambda(\n",
        "            lambda x: cast_to_float_with_shape(ordinal_encoders[col](x)),\n",
        "            output_shape=(1,),\n",
        "            name=f'cast_lambda_{col}'\n",
        "        )(discrete_inputs[col])\n",
        "        for col in discrete_features\n",
        "    ]\n",
        "\n",
        "    embedding_size = 8\n",
        "    embedded_features = [\n",
        "        Flatten()(Embedding(input_dim=categorical_encoders[col].vocabulary_size(), output_dim=embedding_size)(\n",
        "            categorical_encoders[col](categorical_inputs[col])\n",
        "        )) for col in categorical_features\n",
        "    ]\n",
        "\n",
        "    all_features = Concatenate()(processed_continuous + processed_discrete + embedded_features)\n",
        "    return continuous_inputs, discrete_inputs, categorical_inputs, all_features\n",
        "\n",
        "# Build full model\n",
        "continuous_inputs, discrete_inputs, categorical_inputs, processed_features = build_preprocessing_model()\n",
        "x = Dense(128, activation='relu', kernel_initializer='he_normal')(processed_features)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_inputs = list(continuous_inputs.values()) + list(discrete_inputs.values()) + list(categorical_inputs.values())\n",
        "model = Model(inputs=model_inputs, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "# Preprocess datasets\n",
        "def preprocess_batch(features, labels):\n",
        "    inputs = {\n",
        "        **{f\"{col}_input\": features[col] for col in continuous_features},\n",
        "        **{f\"{col}_input\": tf.cast(features[col], tf.int32) for col in discrete_features},\n",
        "        **{f\"{col}_input\": features[col] for col in categorical_features}\n",
        "    }\n",
        "    return inputs, labels\n",
        "\n",
        "train_dataset = train_dataset_raw.map(preprocess_batch).cache()\n",
        "val_dataset = val_dataset_raw.map(preprocess_batch).cache()\n",
        "test_dataset = test_dataset_raw.map(preprocess_batch).cache()\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [EarlyStopping(patience=15,\n",
        "                           restore_best_weights=True,\n",
        "                           monitor='val_loss'),\n",
        "            ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.5,\n",
        "                              patience=15,\n",
        "                              min_lr=1e-6),\n",
        "            ModelCheckpoint('best_logistic_credit_model_tf.keras',\n",
        "                            monitor='val_loss',\n",
        "                            save_best_only=True)\n",
        "            ]\n",
        "\n",
        "# Train\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test loss: {test_loss} - Test accuracy: {test_acc}\")\n",
        "\n",
        "# Save model\n",
        "custom_objects = {\n",
        "    'log1p_with_shape': log1p_with_shape,\n",
        "    'cast_to_float_with_shape': cast_to_float_with_shape\n",
        "}\n",
        "\n",
        "model.save(\"logistic_credit_model_tf.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - accuracy: 0.6645 - loss: 0.6458 - val_accuracy: 0.6600 - val_loss: 0.6495 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7079 - loss: 0.6004 - val_accuracy: 0.6500 - val_loss: 0.6213 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7117 - loss: 0.5798 - val_accuracy: 0.6400 - val_loss: 0.6199 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7109 - loss: 0.5714 - val_accuracy: 0.6600 - val_loss: 0.6177 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7163 - loss: 0.5706 - val_accuracy: 0.6700 - val_loss: 0.5981 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7368 - loss: 0.5480 - val_accuracy: 0.7200 - val_loss: 0.5817 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7428 - loss: 0.5324 - val_accuracy: 0.7300 - val_loss: 0.5742 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7484 - loss: 0.5195 - val_accuracy: 0.7200 - val_loss: 0.5635 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7593 - loss: 0.5077 - val_accuracy: 0.7300 - val_loss: 0.5600 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.5042 - val_accuracy: 0.7300 - val_loss: 0.5534 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7625 - loss: 0.4938 - val_accuracy: 0.7200 - val_loss: 0.5492 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7665 - loss: 0.4759 - val_accuracy: 0.7300 - val_loss: 0.5336 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7705 - loss: 0.4773 - val_accuracy: 0.7400 - val_loss: 0.5188 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7682 - loss: 0.4725 - val_accuracy: 0.7400 - val_loss: 0.5109 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7796 - loss: 0.4609 - val_accuracy: 0.7400 - val_loss: 0.4974 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7686 - loss: 0.4622 - val_accuracy: 0.7500 - val_loss: 0.4945 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7829 - loss: 0.4629 - val_accuracy: 0.7600 - val_loss: 0.4823 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7754 - loss: 0.4537 - val_accuracy: 0.7800 - val_loss: 0.4751 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7786 - loss: 0.4593 - val_accuracy: 0.7700 - val_loss: 0.4671 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7732 - loss: 0.4552 - val_accuracy: 0.7800 - val_loss: 0.4606 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7841 - loss: 0.4481 - val_accuracy: 0.7800 - val_loss: 0.4594 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7874 - loss: 0.4422 - val_accuracy: 0.7600 - val_loss: 0.4557 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7765 - loss: 0.4444 - val_accuracy: 0.7700 - val_loss: 0.4533 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7768 - loss: 0.4398 - val_accuracy: 0.7800 - val_loss: 0.4446 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7919 - loss: 0.4352 - val_accuracy: 0.7700 - val_loss: 0.4407 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7989 - loss: 0.4219 - val_accuracy: 0.8000 - val_loss: 0.4326 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8123 - loss: 0.4097 - val_accuracy: 0.7900 - val_loss: 0.4257 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8026 - loss: 0.4179 - val_accuracy: 0.7800 - val_loss: 0.4204 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8102 - loss: 0.4240 - val_accuracy: 0.7800 - val_loss: 0.4129 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8175 - loss: 0.4093 - val_accuracy: 0.8000 - val_loss: 0.4086 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8152 - loss: 0.4135 - val_accuracy: 0.8200 - val_loss: 0.4066 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8252 - loss: 0.3977 - val_accuracy: 0.7900 - val_loss: 0.4062 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8185 - loss: 0.3962 - val_accuracy: 0.8200 - val_loss: 0.4001 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8311 - loss: 0.3815 - val_accuracy: 0.8300 - val_loss: 0.3964 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8220 - loss: 0.3844 - val_accuracy: 0.8300 - val_loss: 0.3873 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8357 - loss: 0.3648 - val_accuracy: 0.8400 - val_loss: 0.3772 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8259 - loss: 0.3744 - val_accuracy: 0.8500 - val_loss: 0.3737 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8354 - loss: 0.3645 - val_accuracy: 0.8600 - val_loss: 0.3653 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8462 - loss: 0.3571 - val_accuracy: 0.8500 - val_loss: 0.3575 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8544 - loss: 0.3433 - val_accuracy: 0.8700 - val_loss: 0.3472 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8527 - loss: 0.3494 - val_accuracy: 0.8600 - val_loss: 0.3425 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8566 - loss: 0.3339 - val_accuracy: 0.8700 - val_loss: 0.3334 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8532 - loss: 0.3342 - val_accuracy: 0.8800 - val_loss: 0.3312 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8568 - loss: 0.3310 - val_accuracy: 0.8900 - val_loss: 0.3236 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8695 - loss: 0.3226 - val_accuracy: 0.8800 - val_loss: 0.3188 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.8771 - loss: 0.3041 - val_accuracy: 0.8900 - val_loss: 0.3110 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8512 - loss: 0.3153 - val_accuracy: 0.8800 - val_loss: 0.3090 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8599 - loss: 0.2959 - val_accuracy: 0.8900 - val_loss: 0.3046 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8733 - loss: 0.2969 - val_accuracy: 0.8900 - val_loss: 0.2951 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8768 - loss: 0.2913 - val_accuracy: 0.8800 - val_loss: 0.2835 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8720 - loss: 0.2891 - val_accuracy: 0.8800 - val_loss: 0.2804 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8794 - loss: 0.2662 - val_accuracy: 0.8900 - val_loss: 0.2779 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8989 - loss: 0.2570 - val_accuracy: 0.8800 - val_loss: 0.2614 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8887 - loss: 0.2534 - val_accuracy: 0.9000 - val_loss: 0.2684 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8984 - loss: 0.2476 - val_accuracy: 0.8800 - val_loss: 0.2630 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9024 - loss: 0.2395 - val_accuracy: 0.9000 - val_loss: 0.2631 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9056 - loss: 0.2406 - val_accuracy: 0.8900 - val_loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9104 - loss: 0.2369 - val_accuracy: 0.8900 - val_loss: 0.2465 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9096 - loss: 0.2216 - val_accuracy: 0.8900 - val_loss: 0.2379 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9125 - loss: 0.2103 - val_accuracy: 0.8800 - val_loss: 0.2327 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9150 - loss: 0.2133 - val_accuracy: 0.8900 - val_loss: 0.2256 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9201 - loss: 0.2066 - val_accuracy: 0.9300 - val_loss: 0.2238 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9192 - loss: 0.1875 - val_accuracy: 0.9100 - val_loss: 0.2170 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9303 - loss: 0.1882 - val_accuracy: 0.9200 - val_loss: 0.2110 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9196 - loss: 0.2002 - val_accuracy: 0.9200 - val_loss: 0.2183 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9296 - loss: 0.1797 - val_accuracy: 0.9300 - val_loss: 0.2093 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9311 - loss: 0.1716 - val_accuracy: 0.9200 - val_loss: 0.2058 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9329 - loss: 0.1726 - val_accuracy: 0.9300 - val_loss: 0.2097 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9461 - loss: 0.1584 - val_accuracy: 0.9200 - val_loss: 0.2013 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9396 - loss: 0.1551 - val_accuracy: 0.9200 - val_loss: 0.2090 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9380 - loss: 0.1548 - val_accuracy: 0.9300 - val_loss: 0.2000 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9440 - loss: 0.1494 - val_accuracy: 0.9300 - val_loss: 0.2008 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9298 - loss: 0.1567 - val_accuracy: 0.9200 - val_loss: 0.2095 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9516 - loss: 0.1378 - val_accuracy: 0.9300 - val_loss: 0.1926 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9566 - loss: 0.1353 - val_accuracy: 0.9200 - val_loss: 0.1936 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9419 - loss: 0.1360 - val_accuracy: 0.9300 - val_loss: 0.1767 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1350 - val_accuracy: 0.9300 - val_loss: 0.1857 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9553 - loss: 0.1254 - val_accuracy: 0.9400 - val_loss: 0.1718 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.1310 - val_accuracy: 0.9200 - val_loss: 0.1919 - learning_rate: 0.0010\n",
            "Epoch 80/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9420 - loss: 0.1302 - val_accuracy: 0.9300 - val_loss: 0.1745 - learning_rate: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9549 - loss: 0.1170 - val_accuracy: 0.9300 - val_loss: 0.1766 - learning_rate: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9673 - loss: 0.1071 - val_accuracy: 0.9300 - val_loss: 0.1884 - learning_rate: 0.0010\n",
            "Epoch 83/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9471 - loss: 0.1228 - val_accuracy: 0.9300 - val_loss: 0.1661 - learning_rate: 0.0010\n",
            "Epoch 84/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0906 - val_accuracy: 0.9200 - val_loss: 0.1917 - learning_rate: 0.0010\n",
            "Epoch 85/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9591 - loss: 0.1027 - val_accuracy: 0.9300 - val_loss: 0.1778 - learning_rate: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1038 - val_accuracy: 0.9400 - val_loss: 0.1798 - learning_rate: 0.0010\n",
            "Epoch 87/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9681 - loss: 0.1017 - val_accuracy: 0.9300 - val_loss: 0.1809 - learning_rate: 0.0010\n",
            "Epoch 88/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0872 - val_accuracy: 0.9200 - val_loss: 0.1935 - learning_rate: 0.0010\n",
            "Epoch 89/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9559 - loss: 0.1080 - val_accuracy: 0.9400 - val_loss: 0.1661 - learning_rate: 0.0010\n",
            "Epoch 90/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9703 - loss: 0.1008 - val_accuracy: 0.9300 - val_loss: 0.1849 - learning_rate: 0.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9717 - loss: 0.0871 - val_accuracy: 0.9500 - val_loss: 0.1637 - learning_rate: 0.0010\n",
            "Epoch 92/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0854 - val_accuracy: 0.9200 - val_loss: 0.1932 - learning_rate: 0.0010\n",
            "Epoch 93/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9698 - loss: 0.0790 - val_accuracy: 0.9300 - val_loss: 0.1734 - learning_rate: 0.0010\n",
            "Epoch 94/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0784 - val_accuracy: 0.9200 - val_loss: 0.2124 - learning_rate: 0.0010\n",
            "Epoch 95/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9690 - loss: 0.0897 - val_accuracy: 0.9300 - val_loss: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 96/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9760 - loss: 0.0757 - val_accuracy: 0.9200 - val_loss: 0.1947 - learning_rate: 0.0010\n",
            "Epoch 97/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9788 - loss: 0.0692 - val_accuracy: 0.9200 - val_loss: 0.1889 - learning_rate: 0.0010\n",
            "Epoch 98/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9778 - loss: 0.0701 - val_accuracy: 0.9100 - val_loss: 0.2102 - learning_rate: 0.0010\n",
            "Epoch 99/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9758 - loss: 0.0739 - val_accuracy: 0.9300 - val_loss: 0.1828 - learning_rate: 0.0010\n",
            "Epoch 100/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9826 - loss: 0.0602 - val_accuracy: 0.9300 - val_loss: 0.2089 - learning_rate: 0.0010\n",
            "Epoch 101/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.0719 - val_accuracy: 0.9300 - val_loss: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 102/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.0690 - val_accuracy: 0.9200 - val_loss: 0.1923 - learning_rate: 0.0010\n",
            "Epoch 103/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0596 - val_accuracy: 0.9200 - val_loss: 0.1730 - learning_rate: 0.0010\n",
            "Epoch 104/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9812 - loss: 0.0532 - val_accuracy: 0.9200 - val_loss: 0.2020 - learning_rate: 0.0010\n",
            "Epoch 105/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9782 - loss: 0.0679 - val_accuracy: 0.9300 - val_loss: 0.1601 - learning_rate: 0.0010\n",
            "Epoch 106/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0577 - val_accuracy: 0.9200 - val_loss: 0.1858 - learning_rate: 0.0010\n",
            "Epoch 107/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0505 - val_accuracy: 0.9300 - val_loss: 0.1705 - learning_rate: 0.0010\n",
            "Epoch 108/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.0445 - val_accuracy: 0.9300 - val_loss: 0.1760 - learning_rate: 0.0010\n",
            "Epoch 109/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0549 - val_accuracy: 0.9200 - val_loss: 0.1886 - learning_rate: 0.0010\n",
            "Epoch 110/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9770 - loss: 0.0572 - val_accuracy: 0.9300 - val_loss: 0.1721 - learning_rate: 0.0010\n",
            "Epoch 111/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0540 - val_accuracy: 0.9400 - val_loss: 0.2048 - learning_rate: 0.0010\n",
            "Epoch 112/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0473 - val_accuracy: 0.9400 - val_loss: 0.1879 - learning_rate: 0.0010\n",
            "Epoch 113/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.0587 - val_accuracy: 0.9400 - val_loss: 0.2081 - learning_rate: 0.0010\n",
            "Epoch 114/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9875 - loss: 0.0461 - val_accuracy: 0.9400 - val_loss: 0.1978 - learning_rate: 0.0010\n",
            "Epoch 115/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0446 - val_accuracy: 0.9400 - val_loss: 0.2207 - learning_rate: 0.0010\n",
            "Epoch 116/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0397 - val_accuracy: 0.9200 - val_loss: 0.1930 - learning_rate: 0.0010\n",
            "Epoch 117/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0448 - val_accuracy: 0.9300 - val_loss: 0.2178 - learning_rate: 0.0010\n",
            "Epoch 118/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0526 - val_accuracy: 0.9200 - val_loss: 0.2105 - learning_rate: 0.0010\n",
            "Epoch 119/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.0527 - val_accuracy: 0.9300 - val_loss: 0.2083 - learning_rate: 0.0010\n",
            "Epoch 120/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0431 - val_accuracy: 0.9400 - val_loss: 0.2175 - learning_rate: 0.0010\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9600 - loss: 0.1607\n",
            "Test loss: 0.1607057899236679 - Test accuracy: 0.9599999785423279\n"
          ]
        }
      ],
      "source": [
        "### Augment class based code \n",
        "import tensorflow as tf\n",
        "from silence_tensorflow import silence_tensorflow\n",
        "silence_tensorflow()\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate, IntegerLookup, StringLookup\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"LogTransform\")\n",
        "class LogTransform(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.math.log1p(inputs)\n",
        "\n",
        "    def get_config(self):  # Required for serialization\n",
        "        return super().get_config()\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"LogTransform\")\n",
        "class Standardize(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return (inputs - tf.reduce_mean(inputs)) / tf.math.reduce_std(inputs)\n",
        "\n",
        "    def get_config(self):  # Required for serialization\n",
        "        return super().get_config()\n",
        "\n",
        "\n",
        "class CreditDataPreprocessor:\n",
        "    def __init__(self, discrete_features, categorical_features, continuous_features):\n",
        "        self.discrete_features = discrete_features\n",
        "        self.categorical_features = categorical_features\n",
        "        self.continuous_features = continuous_features\n",
        "        \n",
        "        # Initialize encoders\n",
        "        self.ordinal_encoders = {\n",
        "            col: IntegerLookup(output_mode='int', num_oov_indices=1) \n",
        "            for col in discrete_features\n",
        "        }\n",
        "        self.categorical_encoders = {\n",
        "            col: StringLookup(output_mode='int', num_oov_indices=1) \n",
        "            for col in categorical_features\n",
        "        }\n",
        "        \n",
        "    def adapt(self, dataset):\n",
        "        \"\"\"Adapt all encoders to the data\"\"\"\n",
        "        for batch in dataset:\n",
        "            features, _ = batch\n",
        "            for col in self.discrete_features:\n",
        "                self.ordinal_encoders[col].adapt(features[col])\n",
        "            for col in self.categorical_features:\n",
        "                self.categorical_encoders[col].adapt(features[col])\n",
        "    \n",
        "    def preprocess_batch(self, features, labels):\n",
        "        \"\"\"Transform a batch of data\"\"\"\n",
        "        inputs = {\n",
        "            **{f\"{col}_input\": features[col] for col in self.continuous_features},\n",
        "            **{f\"{col}_input\": tf.cast(features[col], tf.int32) for col in self.discrete_features},\n",
        "            **{f\"{col}_input\": features[col] for col in self.categorical_features}\n",
        "        }\n",
        "        return inputs, labels\n",
        "    \n",
        "    def prepare_dataset(self, dataset):\n",
        "        \"\"\"Prepare a dataset for training\"\"\"\n",
        "        return dataset.map(self.preprocess_batch).cache()\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"DiscreteFeatureEncoder\")\n",
        "class DiscreteFeatureEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, encoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        # Mark the layer as built\n",
        "        super().build(input_shape)    \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return tf.cast(self.encoder(inputs), tf.float32)\n",
        "\n",
        "    def get_config(self):\n",
        "        # Serialize the encoder along with other configurations\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"encoder\": self.encoder.get_config()  # Serialize the encoder\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # Deserialize the encoder\n",
        "        encoder_config = config.pop(\"encoder\")\n",
        "        encoder = IntegerLookup.from_config(encoder_config)  # Reconstruct the encoder\n",
        "        return cls(encoder=encoder, **config)\n",
        "\n",
        "\n",
        "class CreditRiskModel(tf.keras.Model):  # Inherit from tf.keras.Model\n",
        "    def __init__(self, preprocessor, embedding_size=8, **kwargs):\n",
        "        super().__init__(**kwargs)  # Ensure proper initialization\n",
        "        self.preprocessor = preprocessor\n",
        "        self.embedding_size = embedding_size\n",
        "        self.model = self.build_model()  # Store Keras model\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Builds and returns a Keras model\"\"\"\n",
        "        continuous_inputs = {\n",
        "            col: Input(shape=(1,), dtype=tf.float32, name=f\"{col}_input\") \n",
        "            for col in self.preprocessor.continuous_features\n",
        "        }\n",
        "        discrete_inputs = {\n",
        "            col: Input(shape=(1,), dtype=tf.int32, name=f\"{col}_input\") \n",
        "            for col in self.preprocessor.discrete_features\n",
        "        }\n",
        "        categorical_inputs = {\n",
        "            col: Input(shape=(1,), dtype=tf.string, name=f\"{col}_input\") \n",
        "            for col in self.preprocessor.categorical_features\n",
        "        }\n",
        "        \n",
        "        processed_features = self._process_features(\n",
        "            continuous_inputs, discrete_inputs, categorical_inputs)\n",
        "        \n",
        "        x = Dense(128, activation='relu', kernel_initializer='he_normal')(processed_features)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "        x = Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "        output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model_inputs = list(continuous_inputs.values()) + list(discrete_inputs.values()) + list(categorical_inputs.values())\n",
        "        return Model(inputs=model_inputs, outputs=output)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass for Keras\"\"\"\n",
        "        return self.model(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Required for serialization\"\"\"\n",
        "        return {\n",
        "            \"embedding_size\": self.embedding_size,\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        \"\"\"Load model from config\"\"\"\n",
        "        return cls(**config)\n",
        "\n",
        "    def save_model(self, path=\"logistic_credit_model_tf.keras\"):\n",
        "        \"\"\"Save the model properly\"\"\"\n",
        "        self.model.save(path)  # Save only the inner Keras model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    def _process_features(self, continuous_inputs, discrete_inputs, categorical_inputs):\n",
        "        log_transform = LogTransform()\n",
        "        standardize = Standardize()\n",
        "    \n",
        "        # Process continuous features\n",
        "        processed_continuous = [\n",
        "            standardize(log_transform(continuous_inputs[col]))\n",
        "            for col in self.preprocessor.continuous_features\n",
        "        ]\n",
        "        \n",
        "        processed_discrete = [\n",
        "            DiscreteFeatureEncoder(self.preprocessor.ordinal_encoders[col])(discrete_inputs[col])\n",
        "            for col in self.preprocessor.discrete_features\n",
        "        ]\n",
        "\n",
        "    \n",
        "        # Process categorical features\n",
        "        embedded_features = [\n",
        "            Flatten()(Embedding(\n",
        "                input_dim=self.preprocessor.categorical_encoders[col].vocabulary_size(),\n",
        "                output_dim=self.embedding_size\n",
        "            )(self.preprocessor.categorical_encoders[col](categorical_inputs[col])))\n",
        "            for col in self.preprocessor.categorical_features\n",
        "        ]\n",
        "    \n",
        "        return Concatenate()(processed_continuous + processed_discrete + embedded_features)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def create_tf_datasets(X, y, train_size=0.8, val_size=0.1, batch_size=128, seed=None):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
        "    dataset = dataset.shuffle(buffer_size=len(X), seed=seed)\n",
        "    n = len(X)\n",
        "    train_size_n = int(n * train_size)\n",
        "    val_size_n = int(n * val_size)\n",
        "    \n",
        "    train_dataset = dataset.take(train_size_n)\n",
        "    val_dataset = dataset.skip(train_size_n).take(val_size_n)\n",
        "    test_dataset = dataset.skip(train_size_n + val_size_n)\n",
        "    \n",
        "    return (\n",
        "        train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "# Load and prepare data\n",
        "credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
        "X = credit_data.data\n",
        "y = credit_data.target.map({'good': 1, 'bad': 0}).values\n",
        "\n",
        "# Define feature columns\n",
        "discrete_features = ['installment_commitment', 'residence_since', 'num_dependents', 'existing_credits']\n",
        "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
        "continuous_features = ['duration', 'credit_amount']\n",
        "\n",
        "# Create datasets\n",
        "seed = 2025\n",
        "train_dataset_raw, val_dataset_raw, test_dataset_raw = create_tf_datasets(X, y, seed=seed)\n",
        "\n",
        "# Initialize and adapt preprocessor\n",
        "preprocessor = CreditDataPreprocessor(\n",
        "    discrete_features=discrete_features,\n",
        "    categorical_features=categorical_features,\n",
        "    continuous_features=continuous_features\n",
        ")\n",
        "preprocessor.adapt(train_dataset_raw)\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = preprocessor.prepare_dataset(train_dataset_raw)\n",
        "val_dataset = preprocessor.prepare_dataset(val_dataset_raw)\n",
        "test_dataset = preprocessor.prepare_dataset(test_dataset_raw)\n",
        "\n",
        "# Create and compile model\n",
        "credit_model = CreditRiskModel(preprocessor)  \n",
        "credit_model.model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                           loss='binary_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_logistic_credit_model_tf.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "credit_model.model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = credit_model.model.evaluate(test_dataset)\n",
        "print(f\"Test loss: {test_loss} - Test accuracy: {test_acc}\")\n",
        "credit_model.save_model()  # Now works correctly\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Define custom objects for deserialization\n",
        "custom_objects = {\n",
        "    \"LogTransform\": LogTransform,\n",
        "    \"Standardize\": Standardize,\n",
        "    \"DiscreteFeatureEncoder\": DiscreteFeatureEncoder\n",
        "}\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"logistic_credit_model_tf.keras\", custom_objects=custom_objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.6482 - loss: 0.6599 - val_accuracy: 0.6600 - val_loss: 0.6688 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6974 - loss: 0.6297 - val_accuracy: 0.6600 - val_loss: 0.6488 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6981 - loss: 0.6207 - val_accuracy: 0.6600 - val_loss: 0.6431 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6983 - loss: 0.6130 - val_accuracy: 0.6600 - val_loss: 0.6393 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6925 - loss: 0.6087 - val_accuracy: 0.6600 - val_loss: 0.6343 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6983 - loss: 0.6024 - val_accuracy: 0.6600 - val_loss: 0.6239 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6987 - loss: 0.5993 - val_accuracy: 0.6600 - val_loss: 0.6121 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7011 - loss: 0.5853 - val_accuracy: 0.6600 - val_loss: 0.5943 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7104 - loss: 0.5527 - val_accuracy: 0.6900 - val_loss: 0.5750 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7075 - loss: 0.5560 - val_accuracy: 0.7300 - val_loss: 0.5612 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7336 - loss: 0.5203 - val_accuracy: 0.7200 - val_loss: 0.5505 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7237 - loss: 0.5101 - val_accuracy: 0.7300 - val_loss: 0.5454 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7279 - loss: 0.5142 - val_accuracy: 0.7500 - val_loss: 0.5420 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7700 - loss: 0.5047 - val_accuracy: 0.7500 - val_loss: 0.5375 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7517 - loss: 0.4961 - val_accuracy: 0.7500 - val_loss: 0.5315 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7525 - loss: 0.4935 - val_accuracy: 0.7500 - val_loss: 0.5234 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7458 - loss: 0.4888 - val_accuracy: 0.7500 - val_loss: 0.5158 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7499 - loss: 0.5010 - val_accuracy: 0.7500 - val_loss: 0.5085 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7598 - loss: 0.4944 - val_accuracy: 0.7400 - val_loss: 0.5010 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7658 - loss: 0.4835 - val_accuracy: 0.7400 - val_loss: 0.4957 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7552 - loss: 0.4751 - val_accuracy: 0.7300 - val_loss: 0.4924 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7493 - loss: 0.4812 - val_accuracy: 0.7300 - val_loss: 0.4905 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7484 - loss: 0.5007 - val_accuracy: 0.7300 - val_loss: 0.4914 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7657 - loss: 0.4803 - val_accuracy: 0.7300 - val_loss: 0.4893 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7594 - loss: 0.4730 - val_accuracy: 0.7500 - val_loss: 0.4849 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7511 - loss: 0.4827 - val_accuracy: 0.7300 - val_loss: 0.4855 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7600 - loss: 0.4722 - val_accuracy: 0.7500 - val_loss: 0.4849 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7620 - loss: 0.4791 - val_accuracy: 0.7300 - val_loss: 0.4872 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7601 - loss: 0.4670 - val_accuracy: 0.7400 - val_loss: 0.4846 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7629 - loss: 0.4668 - val_accuracy: 0.7400 - val_loss: 0.4835 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7582 - loss: 0.4733 - val_accuracy: 0.7500 - val_loss: 0.4783 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7643 - loss: 0.4624 - val_accuracy: 0.7400 - val_loss: 0.4741 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7710 - loss: 0.4532 - val_accuracy: 0.7400 - val_loss: 0.4748 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7584 - loss: 0.4645 - val_accuracy: 0.7500 - val_loss: 0.4746 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7592 - loss: 0.4684 - val_accuracy: 0.7500 - val_loss: 0.4742 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.4560 - val_accuracy: 0.7500 - val_loss: 0.4753 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7670 - loss: 0.4524 - val_accuracy: 0.7600 - val_loss: 0.4753 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7819 - loss: 0.4406 - val_accuracy: 0.7500 - val_loss: 0.4714 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7744 - loss: 0.4447 - val_accuracy: 0.7600 - val_loss: 0.4682 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7809 - loss: 0.4339 - val_accuracy: 0.7600 - val_loss: 0.4625 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7883 - loss: 0.4313 - val_accuracy: 0.7700 - val_loss: 0.4633 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7803 - loss: 0.4434 - val_accuracy: 0.7600 - val_loss: 0.4632 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7846 - loss: 0.4381 - val_accuracy: 0.7800 - val_loss: 0.4612 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7862 - loss: 0.4391 - val_accuracy: 0.7700 - val_loss: 0.4598 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7571 - loss: 0.4256 - val_accuracy: 0.7700 - val_loss: 0.4582 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7889 - loss: 0.4262 - val_accuracy: 0.7800 - val_loss: 0.4520 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7907 - loss: 0.4205 - val_accuracy: 0.7800 - val_loss: 0.4479 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8000 - loss: 0.4169 - val_accuracy: 0.7800 - val_loss: 0.4446 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8060 - loss: 0.4274 - val_accuracy: 0.7800 - val_loss: 0.4435 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8004 - loss: 0.3942 - val_accuracy: 0.8000 - val_loss: 0.4377 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8147 - loss: 0.3904 - val_accuracy: 0.7700 - val_loss: 0.4360 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7989 - loss: 0.4157 - val_accuracy: 0.7800 - val_loss: 0.4364 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8160 - loss: 0.4011 - val_accuracy: 0.7700 - val_loss: 0.4341 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8085 - loss: 0.3999 - val_accuracy: 0.7900 - val_loss: 0.4322 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8077 - loss: 0.3913 - val_accuracy: 0.7800 - val_loss: 0.4286 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8121 - loss: 0.3809 - val_accuracy: 0.7800 - val_loss: 0.4264 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8164 - loss: 0.3722 - val_accuracy: 0.8000 - val_loss: 0.4229 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8383 - loss: 0.3668 - val_accuracy: 0.7800 - val_loss: 0.4206 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8356 - loss: 0.3696 - val_accuracy: 0.7800 - val_loss: 0.4156 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8457 - loss: 0.3652 - val_accuracy: 0.7900 - val_loss: 0.4188 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8428 - loss: 0.3705 - val_accuracy: 0.7900 - val_loss: 0.4143 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8217 - loss: 0.3562 - val_accuracy: 0.7900 - val_loss: 0.4107 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8469 - loss: 0.3536 - val_accuracy: 0.8100 - val_loss: 0.4107 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8444 - loss: 0.3320 - val_accuracy: 0.8100 - val_loss: 0.4067 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8501 - loss: 0.3295 - val_accuracy: 0.8300 - val_loss: 0.3960 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8490 - loss: 0.3278 - val_accuracy: 0.8100 - val_loss: 0.3958 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8381 - loss: 0.3318 - val_accuracy: 0.8400 - val_loss: 0.3993 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8660 - loss: 0.3134 - val_accuracy: 0.8200 - val_loss: 0.3982 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8631 - loss: 0.3077 - val_accuracy: 0.8200 - val_loss: 0.3940 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8631 - loss: 0.3008 - val_accuracy: 0.8400 - val_loss: 0.4056 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8575 - loss: 0.3051 - val_accuracy: 0.8200 - val_loss: 0.3855 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8670 - loss: 0.3098 - val_accuracy: 0.8300 - val_loss: 0.3844 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8571 - loss: 0.2933 - val_accuracy: 0.8400 - val_loss: 0.3869 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8948 - loss: 0.2920 - val_accuracy: 0.8300 - val_loss: 0.3831 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8744 - loss: 0.2890 - val_accuracy: 0.8300 - val_loss: 0.3854 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8769 - loss: 0.2799 - val_accuracy: 0.8500 - val_loss: 0.3812 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8900 - loss: 0.2714 - val_accuracy: 0.8400 - val_loss: 0.3739 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8801 - loss: 0.2743 - val_accuracy: 0.8300 - val_loss: 0.3911 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8787 - loss: 0.2752 - val_accuracy: 0.8500 - val_loss: 0.3702 - learning_rate: 0.0010\n",
            "Epoch 80/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8895 - loss: 0.2613 - val_accuracy: 0.8500 - val_loss: 0.3583 - learning_rate: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.2513 - val_accuracy: 0.8400 - val_loss: 0.3753 - learning_rate: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8954 - loss: 0.2435 - val_accuracy: 0.8500 - val_loss: 0.3671 - learning_rate: 0.0010\n",
            "Epoch 83/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9025 - loss: 0.2343 - val_accuracy: 0.8500 - val_loss: 0.3626 - learning_rate: 0.0010\n",
            "Epoch 84/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9022 - loss: 0.2413 - val_accuracy: 0.8400 - val_loss: 0.3783 - learning_rate: 0.0010\n",
            "Epoch 85/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8966 - loss: 0.2398 - val_accuracy: 0.8500 - val_loss: 0.3706 - learning_rate: 0.0010\n",
            "Epoch 86/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8960 - loss: 0.2390 - val_accuracy: 0.8500 - val_loss: 0.3627 - learning_rate: 0.0010\n",
            "Epoch 87/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9149 - loss: 0.2217 - val_accuracy: 0.8600 - val_loss: 0.3680 - learning_rate: 0.0010\n",
            "Epoch 88/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8966 - loss: 0.2291 - val_accuracy: 0.8500 - val_loss: 0.3740 - learning_rate: 0.0010\n",
            "Epoch 89/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9200 - loss: 0.2229 - val_accuracy: 0.8600 - val_loss: 0.3795 - learning_rate: 0.0010\n",
            "Epoch 90/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8982 - loss: 0.2227 - val_accuracy: 0.8600 - val_loss: 0.3729 - learning_rate: 0.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9198 - loss: 0.2224 - val_accuracy: 0.8800 - val_loss: 0.3555 - learning_rate: 0.0010\n",
            "Epoch 92/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9128 - loss: 0.2206 - val_accuracy: 0.8900 - val_loss: 0.3659 - learning_rate: 0.0010\n",
            "Epoch 93/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9181 - loss: 0.1957 - val_accuracy: 0.8700 - val_loss: 0.3590 - learning_rate: 0.0010\n",
            "Epoch 94/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9126 - loss: 0.2148 - val_accuracy: 0.8800 - val_loss: 0.3670 - learning_rate: 0.0010\n",
            "Epoch 95/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9125 - loss: 0.2121 - val_accuracy: 0.8500 - val_loss: 0.3825 - learning_rate: 0.0010\n",
            "Epoch 96/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9149 - loss: 0.1992 - val_accuracy: 0.8700 - val_loss: 0.3696 - learning_rate: 0.0010\n",
            "Epoch 97/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9190 - loss: 0.1960 - val_accuracy: 0.8800 - val_loss: 0.3607 - learning_rate: 0.0010\n",
            "Epoch 98/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9276 - loss: 0.1821 - val_accuracy: 0.8600 - val_loss: 0.3765 - learning_rate: 0.0010\n",
            "Epoch 99/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9306 - loss: 0.1715 - val_accuracy: 0.8800 - val_loss: 0.3743 - learning_rate: 0.0010\n",
            "Epoch 100/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9259 - loss: 0.1873 - val_accuracy: 0.8900 - val_loss: 0.3501 - learning_rate: 0.0010\n",
            "Epoch 101/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9126 - loss: 0.1866 - val_accuracy: 0.8800 - val_loss: 0.3614 - learning_rate: 0.0010\n",
            "Epoch 102/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9378 - loss: 0.1752 - val_accuracy: 0.8900 - val_loss: 0.3519 - learning_rate: 0.0010\n",
            "Epoch 103/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9386 - loss: 0.1672 - val_accuracy: 0.8800 - val_loss: 0.3580 - learning_rate: 0.0010\n",
            "Epoch 104/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.1667 - val_accuracy: 0.9000 - val_loss: 0.3678 - learning_rate: 0.0010\n",
            "Epoch 105/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9142 - loss: 0.1791 - val_accuracy: 0.8900 - val_loss: 0.3532 - learning_rate: 0.0010\n",
            "Epoch 106/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9292 - loss: 0.1713 - val_accuracy: 0.9000 - val_loss: 0.3668 - learning_rate: 0.0010\n",
            "Epoch 107/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9208 - loss: 0.1701 - val_accuracy: 0.9200 - val_loss: 0.3563 - learning_rate: 0.0010\n",
            "Epoch 108/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9494 - loss: 0.1457 - val_accuracy: 0.9000 - val_loss: 0.3676 - learning_rate: 0.0010\n",
            "Epoch 109/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9428 - loss: 0.1519 - val_accuracy: 0.9000 - val_loss: 0.3718 - learning_rate: 0.0010\n",
            "Epoch 110/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9326 - loss: 0.1621 - val_accuracy: 0.9000 - val_loss: 0.3764 - learning_rate: 0.0010\n",
            "Epoch 111/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9525 - loss: 0.1345 - val_accuracy: 0.9100 - val_loss: 0.3842 - learning_rate: 0.0010\n",
            "Epoch 112/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9486 - loss: 0.1456 - val_accuracy: 0.9100 - val_loss: 0.3700 - learning_rate: 0.0010\n",
            "Epoch 113/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9461 - loss: 0.1471 - val_accuracy: 0.9100 - val_loss: 0.3726 - learning_rate: 0.0010\n",
            "Epoch 114/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9569 - loss: 0.1337 - val_accuracy: 0.9000 - val_loss: 0.3825 - learning_rate: 0.0010\n",
            "Epoch 115/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9304 - loss: 0.1604 - val_accuracy: 0.9000 - val_loss: 0.3947 - learning_rate: 0.0010\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.9100 - loss: 0.3176\n",
            "Test loss: 0.3176409602165222 - Test accuracy: 0.9100000262260437\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.data import AUTOTUNE\n",
        "\n",
        "class LogisticModel(tf.keras.Model):\n",
        "    def __init__(self, continuous_features, discrete_features, categorical_features, \n",
        "                 ordinal_encoders, categorical_encoders, embedding_size=8):\n",
        "        super().__init__()\n",
        "        self.continuous_features = continuous_features\n",
        "        self.discrete_features = discrete_features\n",
        "        self.categorical_features = categorical_features\n",
        "        self.ordinal_encoders = ordinal_encoders\n",
        "        self.categorical_encoders = categorical_encoders\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        # Build model architecture\n",
        "        self._build_model()\n",
        "    \n",
        "    def _build_model(self):\n",
        "        # Inputs\n",
        "        self.continuous_inputs = {col: Input(shape=(1,), dtype=tf.float32, name=f\"{col}_input\") for col in self.continuous_features}\n",
        "        self.discrete_inputs = {col: Input(shape=(1,), dtype=tf.int32, name=f\"{col}_input\") for col in self.discrete_features}\n",
        "        self.categorical_inputs = {col: Input(shape=(1,), dtype=tf.string, name=f\"{col}_input\") for col in self.categorical_features}\n",
        "        \n",
        "        # Continuous processing\n",
        "        self.processed_continuous = [tf.keras.layers.Lambda(lambda x: tf.math.log1p(x))(self.continuous_inputs[col]) for col in self.continuous_features]\n",
        "        \n",
        "        # Discrete processing\n",
        "        self.processed_discrete = [tf.keras.layers.Lambda(lambda x: tf.cast(self.ordinal_encoders[col](x), tf.float32))(self.discrete_inputs[col]) for col in self.discrete_features]\n",
        "        \n",
        "        # Categorical embeddings\n",
        "        self.embedded_features = [\n",
        "            Flatten()(Embedding(input_dim=self.categorical_encoders[col].vocabulary_size(), \n",
        "                                 output_dim=self.embedding_size)(self.categorical_encoders[col](self.categorical_inputs[col])))\n",
        "            for col in self.categorical_features\n",
        "        ]\n",
        "        \n",
        "        # Concatenate features\n",
        "        self.all_features = Concatenate()(self.processed_continuous + self.processed_discrete + self.embedded_features)\n",
        "        \n",
        "        # Dense layers\n",
        "        x = Dense(128, activation='relu', kernel_initializer='he_normal')(self.all_features)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "        x = Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
        "        x = tf.keras.layers.Dropout(0.1)(x)\n",
        "        output = Dense(1, activation='sigmoid')(x)\n",
        "        \n",
        "        # Create model\n",
        "        self.model = Model(inputs=list(self.continuous_inputs.values()) + \n",
        "                                 list(self.discrete_inputs.values()) + \n",
        "                                 list(self.categorical_inputs.values()), \n",
        "                           outputs=output)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    def get_config(self):\n",
        "        return {\"continuous_features\": self.continuous_features,\n",
        "                \"discrete_features\": self.discrete_features,\n",
        "                \"categorical_features\": self.categorical_features}\n",
        "    \n",
        "    def compile_model(self, learning_rate=0.001):\n",
        "        self.model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
        "                           loss='binary_crossentropy', \n",
        "                           metrics=['accuracy'])\n",
        "    \n",
        "    def fit_model(self, train_dataset, val_dataset, epochs=50):\n",
        "        callbacks = [\n",
        "            EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6),\n",
        "            ModelCheckpoint('best_logistic_credit_model_tf.keras', monitor='val_loss', save_best_only=True)\n",
        "        ]\n",
        "        return self.model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, callbacks=callbacks)\n",
        "    \n",
        "    def evaluate_model(self, test_dataset):\n",
        "        return self.model.evaluate(test_dataset)\n",
        "    \n",
        "    def save_model(self, path=\"logistic_credit_model_tf.keras\"):\n",
        "        self.model.save(path)\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
        "X = credit_data.data\n",
        "y = credit_data.target.map({'good': 1, 'bad': 0}).values\n",
        "\n",
        "# Define feature columns\n",
        "discrete_features = ['installment_commitment', 'residence_since', 'num_dependents', 'existing_credits']\n",
        "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
        "continuous_features = ['duration', 'credit_amount']\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "def create_tf_datasets(X, y, train_size=0.8, val_size=0.1, batch_size=128, seed=None):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
        "    dataset = dataset.shuffle(buffer_size=len(X), seed=seed)\n",
        "    n = len(X)\n",
        "    train_size = int(n * train_size)\n",
        "    val_size = int(n * val_size)\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size).take(val_size)\n",
        "    test_dataset = dataset.skip(train_size + val_size)\n",
        "    return (\n",
        "        train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "        test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "seed = 2025\n",
        "train_dataset_raw, val_dataset_raw, test_dataset_raw = create_tf_datasets(X, y, seed=seed)\n",
        "\n",
        "# Adapt preprocessing layers\n",
        "def adapt_preprocessing_layers(dataset):\n",
        "    ordinal_encoders = {col: tf.keras.layers.IntegerLookup(output_mode='int', num_oov_indices=1) for col in discrete_features}\n",
        "    categorical_encoders = {col: tf.keras.layers.StringLookup(output_mode='int', num_oov_indices=1) for col in categorical_features}\n",
        "\n",
        "    for batch in dataset:\n",
        "        features, _ = batch\n",
        "        for col in discrete_features:\n",
        "            ordinal_encoders[col].adapt(features[col])\n",
        "        for col in categorical_features:\n",
        "            categorical_encoders[col].adapt(features[col])\n",
        "\n",
        "    return ordinal_encoders, categorical_encoders\n",
        "\n",
        "ordinal_encoders, categorical_encoders = adapt_preprocessing_layers(train_dataset_raw)\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_batch(features, labels):\n",
        "    inputs = {\n",
        "        **{f\"{col}_input\": features[col] for col in continuous_features},\n",
        "        **{f\"{col}_input\": tf.cast(features[col], tf.int32) for col in discrete_features},\n",
        "        **{f\"{col}_input\": features[col] for col in categorical_features}\n",
        "    }\n",
        "    return inputs, labels\n",
        "\n",
        "train_dataset = train_dataset_raw.map(preprocess_batch).cache()\n",
        "val_dataset = val_dataset_raw.map(preprocess_batch).cache()\n",
        "test_dataset = test_dataset_raw.map(preprocess_batch).cache()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticModel(continuous_features, discrete_features, categorical_features, ordinal_encoders, categorical_encoders)\n",
        "model.compile_model(learning_rate=0.001)\n",
        "model.fit_model(train_dataset, val_dataset, epochs=200)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate_model(test_dataset)\n",
        "print(f\"Test loss: {test_loss} - Test accuracy: {test_acc}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_model(\"logistic_credit_model_tf.keras\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
