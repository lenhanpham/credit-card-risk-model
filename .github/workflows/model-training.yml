name: Model Training and Evaluation

on:
  schedule:
    - cron: '0 0 * * 0'  # Run weekly on Sunday at midnight
  workflow_dispatch:  # Allow manual triggering

jobs:
  train-and-evaluate:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Train model
      run: |
        python -m src.main --mode train --track_with_mlflow
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
    
    - name: Evaluate model
      run: |
        python -m src.main --mode mlflow_best --mlflow_metric val_accuracy
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
    
    - name: Generate model report
      run: |
        python -m src.main --mode visualize --track_with_mlflow
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
    
    - name: Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: model-artifacts
        path: |
          models/
          reports/figures/
          mlruns/
    
    - name: Check model performance
      run: |
        python -c "
        import json
        import sys
        with open('models/evaluation_metrics.json') as f:
            metrics = json.load(f)
        if metrics['test_accuracy'] < 0.75:  # Set your threshold
            print('Model accuracy below threshold')
            sys.exit(1)
        " 